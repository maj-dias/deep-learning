{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-03T23:06:33.5094Z",
     "iopub.status.busy": "2024-08-03T23:06:33.508719Z",
     "iopub.status.idle": "2024-08-03T23:06:45.934194Z",
     "shell.execute_reply": "2024-08-03T23:06:45.933168Z",
     "shell.execute_reply.started": "2024-08-03T23:06:33.509368Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#!pip install -U efficientnet -qq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-03T23:06:49.75293Z",
     "iopub.status.busy": "2024-08-03T23:06:49.752539Z",
     "iopub.status.idle": "2024-08-03T23:06:53.891814Z",
     "shell.execute_reply": "2024-08-03T23:06:53.891Z",
     "shell.execute_reply.started": "2024-08-03T23:06:49.752894Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow.keras.layers as tfl\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.initializers import random_uniform, glorot_uniform\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import * \n",
    "import os\n",
    "import shutil\n",
    "import json\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-03T23:06:57.814188Z",
     "iopub.status.busy": "2024-08-03T23:06:57.813542Z",
     "iopub.status.idle": "2024-08-03T23:06:57.819118Z",
     "shell.execute_reply": "2024-08-03T23:06:57.818013Z",
     "shell.execute_reply.started": "2024-08-03T23:06:57.814158Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Creating a function to streamline the Train data set   \n",
    "def train_img_path(id_str):\n",
    "    return os.path.join(r\"train\", f\"{id_str}.tif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-03T23:07:17.818188Z",
     "iopub.status.busy": "2024-08-03T23:07:17.817803Z",
     "iopub.status.idle": "2024-08-03T23:07:18.063937Z",
     "shell.execute_reply": "2024-08-03T23:07:18.063042Z",
     "shell.execute_reply.started": "2024-08-03T23:07:17.81816Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "example_path = \"train/f38a6374c348f90b587e046aac6079959adf3835.tif\"\n",
    "example_img = Image.open(example_path)\n",
    "example_array = np.array(example_img)\n",
    "print(f\"Image Shape = {example_array.shape}\")\n",
    "plt.imshow(example_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-03T23:07:24.472102Z",
     "iopub.status.busy": "2024-08-03T23:07:24.471729Z",
     "iopub.status.idle": "2024-08-03T23:07:25.258341Z",
     "shell.execute_reply": "2024-08-03T23:07:25.25739Z",
     "shell.execute_reply.started": "2024-08-03T23:07:24.472073Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_labels_df = pd.read_csv('train_labels.csv')\n",
    "train_labels_df[\"filename\"] = train_labels_df[\"id\"].apply(train_img_path)\n",
    "train_labels_df[\"label\"] = train_labels_df[\"label\"].astype(str)\n",
    "train_labels_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-03T23:07:27.550017Z",
     "iopub.status.busy": "2024-08-03T23:07:27.549626Z",
     "iopub.status.idle": "2024-08-03T23:07:27.556105Z",
     "shell.execute_reply": "2024-08-03T23:07:27.555163Z",
     "shell.execute_reply.started": "2024-08-03T23:07:27.549988Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_labels_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-03T23:07:27.814223Z",
     "iopub.status.busy": "2024-08-03T23:07:27.813919Z",
     "iopub.status.idle": "2024-08-03T23:07:27.820093Z",
     "shell.execute_reply": "2024-08-03T23:07:27.819243Z",
     "shell.execute_reply.started": "2024-08-03T23:07:27.814198Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_labels_df[\"label\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-03T23:07:29.764309Z",
     "iopub.status.busy": "2024-08-03T23:07:29.76397Z",
     "iopub.status.idle": "2024-08-03T23:07:29.800615Z",
     "shell.execute_reply": "2024-08-03T23:07:29.799643Z",
     "shell.execute_reply.started": "2024-08-03T23:07:29.764284Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "set(train_labels_df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-03T23:07:31.192784Z",
     "iopub.status.busy": "2024-08-03T23:07:31.19239Z",
     "iopub.status.idle": "2024-08-03T23:07:31.75125Z",
     "shell.execute_reply": "2024-08-03T23:07:31.75025Z",
     "shell.execute_reply.started": "2024-08-03T23:07:31.192754Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "ax = sns.countplot(data=train_labels_df , x=train_labels_df['label'])\n",
    "\n",
    "plt.xlabel('classes 0=not cancerous , 1=cancerous')\n",
    "plt.ylabel('Number of Recourd')\n",
    "plt.title('Count of images in each class', fontsize=20)\n",
    "ax.bar_label(ax.containers[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 220,025 images in the train data set with 2 unique labels. 0 for not cancerous and 1 for cancerous tissues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label 0 = Not-Cancerous\n",
    "## Label 1 = Cancerous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-03T23:07:35.883221Z",
     "iopub.status.busy": "2024-08-03T23:07:35.882579Z",
     "iopub.status.idle": "2024-08-03T23:07:35.925796Z",
     "shell.execute_reply": "2024-08-03T23:07:35.924809Z",
     "shell.execute_reply.started": "2024-08-03T23:07:35.883192Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_labels_df['label'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-03T23:07:37.811942Z",
     "iopub.status.busy": "2024-08-03T23:07:37.811212Z",
     "iopub.status.idle": "2024-08-03T23:07:37.985057Z",
     "shell.execute_reply": "2024-08-03T23:07:37.984204Z",
     "shell.execute_reply.started": "2024-08-03T23:07:37.811901Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sample_data = np.empty((100, 96, 96, 3), dtype=np.uint8)\n",
    "sample_labels = np.empty(100, dtype=np.int8)\n",
    "for i in range(len(train_labels_df))[:100]:\n",
    "    img_path = train_img_path(train_labels_df['id'][i])\n",
    "    img = Image.open(img_path)\n",
    "    sample_data[i] = np.array(img)\n",
    "    sample_labels[i] = train_labels_df['label'][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-03T23:07:40.570419Z",
     "iopub.status.busy": "2024-08-03T23:07:40.569431Z",
     "iopub.status.idle": "2024-08-03T23:07:41.174145Z",
     "shell.execute_reply": "2024-08-03T23:07:41.173257Z",
     "shell.execute_reply.started": "2024-08-03T23:07:40.570382Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"Non-Cancerous Images\")\n",
    "\n",
    "selected_images = np.random.choice(sample_data[sample_labels == 0].shape[0], 12, replace=False)\n",
    "grid_size = int(np.ceil(np.sqrt(12)))\n",
    "\n",
    "fig, axs = plt.subplots(grid_size, grid_size, figsize=(5, 5))\n",
    "\n",
    "for i, ax in enumerate(axs.flatten()):\n",
    "    if i < 12:\n",
    "        ax.imshow(sample_data[sample_labels == 0][selected_images[i]])\n",
    "        ax.axis('off') \n",
    "    else:\n",
    "        fig.delaxes(ax) \n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-03T23:07:58.828548Z",
     "iopub.status.busy": "2024-08-03T23:07:58.827872Z",
     "iopub.status.idle": "2024-08-03T23:07:59.633107Z",
     "shell.execute_reply": "2024-08-03T23:07:59.632312Z",
     "shell.execute_reply.started": "2024-08-03T23:07:58.828517Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"Cancerous Images\")\n",
    "\n",
    "selected_images = np.random.choice(sample_data[sample_labels == 1].shape[0], 12, replace=False)\n",
    "grid_size = int(np.ceil(np.sqrt(12)))\n",
    "\n",
    "fig, axs = plt.subplots(grid_size, grid_size, figsize=(5, 5))\n",
    "\n",
    "for i, ax in enumerate(axs.flatten()):\n",
    "    if i < 12:\n",
    "        ax.imshow(sample_data[sample_labels == 1][selected_images[i]])\n",
    "        ax.axis('off') \n",
    "    else:\n",
    "        fig.delaxes(ax) \n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Designing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part we will perform various steps required to properly create the Resnet 50 model. We will load the data from the disk, specify train and validation data generators while creating test generator for the final submission.\n",
    "\n",
    "We will then create a modified Resnet 50 suited for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-03T23:08:28.17089Z",
     "iopub.status.busy": "2024-08-03T23:08:28.170517Z",
     "iopub.status.idle": "2024-08-03T23:08:28.363306Z",
     "shell.execute_reply": "2024-08-03T23:08:28.362528Z",
     "shell.execute_reply.started": "2024-08-03T23:08:28.170863Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_path = \"/kaggle/input/histopathologic-cancer-detection/test\"\n",
    "test_ids = [filename[:-4] for filename in os.listdir(test_path)]\n",
    "test_filenames = [os.path.join(test_path, filename) for filename in os.listdir(test_path)]\n",
    "test_df = pd.DataFrame()\n",
    "test_df[\"id\"] = test_ids\n",
    "test_df[\"filename\"] = test_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-03T23:08:33.651211Z",
     "iopub.status.busy": "2024-08-03T23:08:33.650845Z",
     "iopub.status.idle": "2024-08-03T23:08:33.655866Z",
     "shell.execute_reply": "2024-08-03T23:08:33.654899Z",
     "shell.execute_reply.started": "2024-08-03T23:08:33.651184Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1/255, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-03T23:09:48.748387Z",
     "iopub.status.busy": "2024-08-03T23:09:48.747431Z",
     "iopub.status.idle": "2024-08-03T23:09:49.97641Z",
     "shell.execute_reply": "2024-08-03T23:09:49.975667Z",
     "shell.execute_reply.started": "2024-08-03T23:09:48.748349Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_generator = datagen.flow_from_dataframe(\n",
    "    shuffle = True,\n",
    "    dataframe = train_labels_df,\n",
    "    x_col = \"filename\",\n",
    "    y_col = \"label\",\n",
    "    target_size = (96, 96),\n",
    "    color_mode = \"rgb\",\n",
    "    batch_size = 32,\n",
    "    class_mode = \"binary\",\n",
    "    subset = \"training\",\n",
    "    validate_filenames = False,\n",
    "    seed = 10\n",
    ")\n",
    "\n",
    "validation_generator = datagen.flow_from_dataframe(\n",
    "    shuffle = True,\n",
    "    dataframe=train_labels_df,\n",
    "    x_col = \"filename\",\n",
    "    y_col = \"label\",\n",
    "    target_size=(96, 96),\n",
    "    color_mode = \"rgb\",\n",
    "    batch_size = 32,\n",
    "    class_mode = \"binary\",\n",
    "    subset = \"validation\",\n",
    "    validate_filenames = False,\n",
    "    seed = 10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-03T23:09:53.611034Z",
     "iopub.status.busy": "2024-08-03T23:09:53.610666Z",
     "iopub.status.idle": "2024-08-03T23:09:53.731636Z",
     "shell.execute_reply": "2024-08-03T23:09:53.730858Z",
     "shell.execute_reply.started": "2024-08-03T23:09:53.611006Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_generator = datagen.flow_from_dataframe(\n",
    "    dataframe = test_df,\n",
    "    x_col = \"filename\",\n",
    "    y_col = None,\n",
    "    target_size = (96, 96),\n",
    "    color_mode = \"rgb\",\n",
    "    batch_size = 64,\n",
    "    shuffle = False,\n",
    "    class_mode = None,\n",
    "    validate_filenames = False,\n",
    "    seed = 10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-03T23:10:02.128312Z",
     "iopub.status.busy": "2024-08-03T23:10:02.127419Z",
     "iopub.status.idle": "2024-08-03T23:10:02.132288Z",
     "shell.execute_reply": "2024-08-03T23:10:02.131332Z",
     "shell.execute_reply.started": "2024-08-03T23:10:02.128277Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_steps = 176020//32  # 8000 images for training\n",
    "val_steps = 44005//32  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will create Resnet50 model.\n",
    "\n",
    "It is to be noted that we can actually use transfer learning and import the model and its trained parameters based on imagenet from the tensorflow API. But for this project we will create a modified model.\n",
    "\n",
    "There will be two types of blocks, identity blocks where input and output dimension remains the same, and convolutional blocks where input and output dimensions are allowed to be changed. In both blocks we will use strong skip connections.\n",
    "\n",
    "After convolutional we will use fully collected layers with output being a dense Sigmoid unit.\n",
    "\n",
    "In the end we will have a Resnet model with 50 layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-03T23:10:06.201764Z",
     "iopub.status.busy": "2024-08-03T23:10:06.200881Z",
     "iopub.status.idle": "2024-08-03T23:10:06.211393Z",
     "shell.execute_reply": "2024-08-03T23:10:06.210416Z",
     "shell.execute_reply.started": "2024-08-03T23:10:06.201729Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def identity_block(X, f, filters, training=True, initializer = random_uniform):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
    "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
    "    training -- True: Behave in training mode\n",
    "                False: Behave in inference mode\n",
    "    initializer -- to set up the initial weights of a layer. Equals to random uniform initializer\n",
    "    \n",
    "    Returns:\n",
    "    X -- output of the identity block, tensor of shape (m, n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Filters\n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    # Save the input value. You'll need this later to add back to the main path. \n",
    "    X_shortcut = X\n",
    "    \n",
    "    # First component of main path\n",
    "    X = tfl.Conv2D(filters = F1, kernel_size = 1, strides = (1,1), padding = 'valid', kernel_initializer = initializer(seed=0))(X)\n",
    "    X = tfl.BatchNormalization(axis = 3)(X, training = training) # Default axis\n",
    "    X = tfl.Activation('relu')(X)\n",
    "    \n",
    "    ## Set the padding = 'same'\n",
    "    X = tfl.Conv2D(filters = F2, kernel_size = f, strides = 1, padding = 'same', kernel_initializer = initializer(seed=0))(X)\n",
    "    X = tfl.BatchNormalization(axis = 3)(X, training = training)\n",
    "    X = tfl.Activation('relu')(X)\n",
    "\n",
    "\n",
    "    ## Set the padding = 'valid'\n",
    "    X = tfl.Conv2D(filters = F3, kernel_size = 1, strides = 1, padding = 'valid', kernel_initializer = initializer(seed = 0))(X)\n",
    "    X = tfl.BatchNormalization(axis = 3)(X, training = training) \n",
    "    \n",
    "    ## Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n",
    "    X = tfl.Add()([X, X_shortcut])\n",
    "    X = tfl.Activation('relu')(X)\n",
    "\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-03T23:10:19.550504Z",
     "iopub.status.busy": "2024-08-03T23:10:19.549747Z",
     "iopub.status.idle": "2024-08-03T23:10:19.573811Z",
     "shell.execute_reply": "2024-08-03T23:10:19.572789Z",
     "shell.execute_reply.started": "2024-08-03T23:10:19.550461Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def convolutional_block(X, f, filters, s = 2, training=True, initializer = glorot_uniform):\n",
    "    \"\"\"\n",
    "    Implementation of the convolutional block\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
    "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
    "    s -- Integer, specifying the stride to be used\n",
    "    training -- True: Behave in training mode\n",
    "                False: Behave in inference mode\n",
    "    initializer -- to set up the initial weights of a layer. Equals to Glorot uniform initializer, \n",
    "                   also called Xavier uniform initializer.\n",
    "    \n",
    "    Returns:\n",
    "    X -- output of the convolutional block, tensor of shape (m, n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Filters\n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    # Save the input value\n",
    "    X_shortcut = X\n",
    "\n",
    "    X = tfl.Conv2D(filters = F1, kernel_size = 1, strides = (s, s), padding='valid', kernel_initializer = initializer(seed=0))(X)\n",
    "    X = tfl.BatchNormalization(axis = 3)(X, training=training)\n",
    "    X = tfl.Activation('relu')(X)\n",
    "    \n",
    "    X = tfl.Conv2D(filters = F2, kernel_size = (f,f), strides = 1, padding='same', kernel_initializer = initializer(seed=0))(X) \n",
    "    X = tfl.BatchNormalization(axis = 3)(X, training=training)\n",
    "    X = tfl.Activation('relu')(X) \n",
    "\n",
    "    X = tfl.Conv2D(filters = F3, kernel_size = 1, strides = 1, padding='valid', kernel_initializer = initializer(seed=0))(X)\n",
    "    X = tfl.BatchNormalization(axis = 3)(X, training=training) \n",
    "\n",
    "    X_shortcut = tfl.Conv2D(filters = F3, kernel_size = (1,1), strides = (s, s), padding='valid', kernel_initializer = initializer(seed=0))(X_shortcut)\n",
    "    X_shortcut = tfl.BatchNormalization(axis = 3)(X_shortcut, training=training)\n",
    "    \n",
    "    X = tfl.Add()([X, X_shortcut])\n",
    "    X = tfl.Activation('relu')(X)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-03T23:10:31.267172Z",
     "iopub.status.busy": "2024-08-03T23:10:31.266823Z",
     "iopub.status.idle": "2024-08-03T23:10:31.297083Z",
     "shell.execute_reply": "2024-08-03T23:10:31.295926Z",
     "shell.execute_reply.started": "2024-08-03T23:10:31.267146Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def ResNet50(input_shape = (96, 96, 3)):\n",
    "    \"\"\"\n",
    "    Stage-wise implementation of the architecture of the popular ResNet50:\n",
    "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
    "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> FLATTEN -> DENSE \n",
    "\n",
    "    Arguments:\n",
    "    input_shape -- shape of the images of the dataset\n",
    "\n",
    "    Returns:\n",
    "    model -- a Model() instance in Keras\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the input as a tensor with shape input_shape\n",
    "    X_input = tfl.Input(input_shape)\n",
    "\n",
    "    \n",
    "    # Zero-Padding\n",
    "    X = tfl.ZeroPadding2D((3, 3))(X_input)\n",
    "    \n",
    "    # Stage 1\n",
    "    X = tfl.Conv2D(96, (7, 7), strides = (2, 2), kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = tfl.BatchNormalization(axis = 3)(X)\n",
    "    X = tfl.Activation('relu')(X)\n",
    "    X = tfl.MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
    "\n",
    "    # Stage 2\n",
    "    X = convolutional_block(X, f = 3, filters = [64, 64, 256], s = 1)\n",
    "    X = identity_block(X, 3, [64, 64, 256])\n",
    "    X = identity_block(X, 3, [64, 64, 256])\n",
    "\n",
    "    ### START CODE HERE\n",
    "    \n",
    "    # Use the instructions above in order to implement all of the Stages below\n",
    "    # Make sure you don't miss adding any required parameter\n",
    "    \n",
    "    ## Stage 3 (≈4 lines)\n",
    "    # `convolutional_block` with correct values of `f`, `filters` and `s` for this stage\n",
    "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], s = 2)\n",
    "    \n",
    "    # the 3 `identity_block` with correct values of `f` and `filters` for this stage\n",
    "    X = identity_block(X, 3, [128, 128, 512])\n",
    "    X = identity_block(X, 3, [128, 128, 512])\n",
    "    X = identity_block(X, 3, [128, 128, 512])\n",
    "\n",
    "    # Stage 4 (≈6 lines)\n",
    "    # add `convolutional_block` with correct values of `f`, `filters` and `s` for this stage\n",
    "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], s = 2)\n",
    "    \n",
    "    # the 5 `identity_block` with correct values of `f` and `filters` for this stage\n",
    "    X = identity_block(X, 3, [256, 256, 1024])\n",
    "    X = identity_block(X, 3, [256, 256, 1024])\n",
    "    X = identity_block(X, 3, [256, 256, 1024])\n",
    "    X = identity_block(X, 3, [256, 256, 1024])\n",
    "    X = identity_block(X, 3, [256, 256, 1024])\n",
    "\n",
    "    # Stage 5 (≈3 lines)\n",
    "    # add `convolutional_block` with correct values of `f`, `filters` and `s` for this stage\n",
    "    X = convolutional_block(X, f = 3, filters = [512, 512, 2048], s = 2)\n",
    "    \n",
    "    # the 2 `identity_block` with correct values of `f` and `filters` for this stage\n",
    "    X = identity_block(X, 3, [512, 512, 2048])\n",
    "    X = identity_block(X, 3, [512, 512, 2048])\n",
    "\n",
    "    # AVGPOOL (≈1 line). Use \"X = AveragePooling2D()(X)\"\n",
    "    X = tfl.AveragePooling2D(pool_size = (2,2))(X)\n",
    "    \n",
    "\n",
    "    # output layer\n",
    "    X = tfl.Flatten()(X)\n",
    "    X = tfl.Dense(1, kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    \n",
    "    \n",
    "    # Create model\n",
    "    model = Model(inputs = X_input, outputs = X)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-03T23:10:34.095212Z",
     "iopub.status.busy": "2024-08-03T23:10:34.094525Z",
     "iopub.status.idle": "2024-08-03T23:10:35.787097Z",
     "shell.execute_reply": "2024-08-03T23:10:35.786194Z",
     "shell.execute_reply.started": "2024-08-03T23:10:34.095177Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = ResNet50(input_shape = (96, 96, 3))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above is the model summary. We have 23,551,681 trainable parameters. If we use more deeper network number of parameters will increase with possible increase in Accuracy or AUC. But for this model we will use resnet 50 only."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-03T23:14:22.53114Z",
     "iopub.status.busy": "2024-08-03T23:14:22.53073Z",
     "iopub.status.idle": "2024-08-03T23:14:22.537348Z",
     "shell.execute_reply": "2024-08-03T23:14:22.536421Z",
     "shell.execute_reply.started": "2024-08-03T23:14:22.53111Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(url=\"https://wisdomml.in/wp-content/uploads/2023/03/resnet_bannner.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part we will use the model created and fit the model with Adam optimizer and loss as binary cross entropy. We have used from logits = True for better accuracy. If reader wants to avoid it they can modify the last output layer in Resnet50 above and make the Activation function as sigmoid instead of linear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create F1 - Score Metric for Classification Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-03T23:21:15.387823Z",
     "iopub.status.busy": "2024-08-03T23:21:15.387162Z",
     "iopub.status.idle": "2024-08-03T23:21:15.396241Z",
     "shell.execute_reply": "2024-08-03T23:21:15.395375Z",
     "shell.execute_reply.started": "2024-08-03T23:21:15.387787Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from tensorflow.keras import backend as K\n",
    "\n",
    "# def f1_score(y_true, y_pred):\n",
    "#     def recall(y_true, y_pred):\n",
    "#         true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "#         possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "#         recall = true_positives / (possible_positives + K.epsilon())\n",
    "#         return recall\n",
    "\n",
    "#     def precision(y_true, y_pred):\n",
    "#         true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "#         predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "#         precision = true_positives / (predicted_positives + K.epsilon())\n",
    "#         return precision\n",
    "\n",
    "#     precision = precision(y_true, y_pred)\n",
    "#     recall = recall(y_true, y_pred)\n",
    "#     f1 = 2 * ((precision * recall) / (precision + recall + K.epsilon()))\n",
    "#     return f1\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "    y_pred = tf.math.round(tf.math.sigmoid(y_pred))  # Convert logits to binary predictions\n",
    "    tp = K.sum(K.cast(y_true * y_pred, 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1 - y_true) * y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true * (1 - y_pred), 'float'), axis=0)\n",
    "    \n",
    "    precision = tp / (tp + fp + K.epsilon())\n",
    "    recall = tp / (tp + fn + K.epsilon())\n",
    "    \n",
    "    f1 = 2 * precision * recall / (precision + recall + K.epsilon())\n",
    "    return K.mean(f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-03T23:21:23.368039Z",
     "iopub.status.busy": "2024-08-03T23:21:23.367121Z",
     "iopub.status.idle": "2024-08-03T23:21:23.390159Z",
     "shell.execute_reply": "2024-08-03T23:21:23.389252Z",
     "shell.execute_reply.started": "2024-08-03T23:21:23.368004Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer = tf.keras.optimizers.Nadam(learning_rate = 0.0001),\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits = True),\n",
    "              metrics=['accuracy', tf.keras.metrics.AUC(), f1_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-03T23:21:32.594909Z",
     "iopub.status.busy": "2024-08-03T23:21:32.594178Z",
     "iopub.status.idle": "2024-08-04T00:08:53.157147Z",
     "shell.execute_reply": "2024-08-04T00:08:53.156244Z",
     "shell.execute_reply.started": "2024-08-03T23:21:32.594877Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch = train_steps,\n",
    "    validation_data = validation_generator,\n",
    "    validation_steps = val_steps,\n",
    "    epochs = 10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T00:10:40.132231Z",
     "iopub.status.busy": "2024-08-04T00:10:40.131875Z",
     "iopub.status.idle": "2024-08-04T00:10:40.141888Z",
     "shell.execute_reply": "2024-08-04T00:10:40.140817Z",
     "shell.execute_reply.started": "2024-08-04T00:10:40.132204Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def merge_history(hlist):\n",
    "    history = {}\n",
    "    for k in hlist[0].history.keys():\n",
    "        history[k] = sum([h.history[k] for h in hlist], [])\n",
    "    return history\n",
    "\n",
    "def vis_training(h, start=1):\n",
    "    epoch_range = range(start, len(h['loss'])+1)\n",
    "    s = slice(start-1, None)\n",
    "\n",
    "    plt.figure(figsize=[14,4])\n",
    "\n",
    "    n = int(len(h.keys()) / 2)\n",
    "\n",
    "    for i in range(n):\n",
    "        k = list(h.keys())[i]\n",
    "        plt.subplot(1,n,i+1)\n",
    "        plt.plot(epoch_range, h[k][s], label='Training')\n",
    "        plt.plot(epoch_range, h['val_' + k][s], label='Validation')\n",
    "        plt.xlabel('Epoch'); plt.ylabel(k); plt.title(k)\n",
    "        plt.grid()\n",
    "        plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T00:10:57.049871Z",
     "iopub.status.busy": "2024-08-04T00:10:57.049454Z",
     "iopub.status.idle": "2024-08-04T00:10:58.02584Z",
     "shell.execute_reply": "2024-08-04T00:10:58.024895Z",
     "shell.execute_reply.started": "2024-08-04T00:10:57.049833Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "history_modelrestnet = merge_history([history])\n",
    "vis_training(history_modelrestnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It takes around 2 hours to train the model with 10 epochs and Kaggle P100 GPU. We can increase the number of epochs but only Training loss decrease for some time after 10 epochs with little change in validation loss and accuracy. In fact we can see from above that after 6th Epoch Validation Accruacy has not changed much.\n",
    "\n",
    "So, it will not be efficient to train with more epochs but readers can do it if they have resources and time for this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we have used a threshold of 0.5 which is just assumed and is totally not correct. There was no decision boundary given with the dataset so we cant use above metrics to test the performance of the model.\n",
    "\n",
    "In order to test the model performance we need to create a submission and get the AUC we will obtain from such submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T00:12:10.715607Z",
     "iopub.status.busy": "2024-08-04T00:12:10.715162Z",
     "iopub.status.idle": "2024-08-04T00:12:11.435813Z",
     "shell.execute_reply": "2024-08-04T00:12:11.434939Z",
     "shell.execute_reply.started": "2024-08-04T00:12:10.715566Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "F1_score = history.history['f1_score']\n",
    "F1_score_valid = history.history['val_f1_score']\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "# Plot Training and Validation Accuracy\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "# Plot Training and Validation Loss\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.ylim([0, max(max(loss), max(val_loss))])\n",
    "plt.title('Training and Validation Loss')\n",
    "\n",
    "# Plot Training and Validation F1 Score\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.plot(F1_score, label='Training F1 Score')\n",
    "plt.plot(F1_score_valid, label='Validation F1 Score')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.ylim([0, 1])\n",
    "plt.title('Training and Validation F1 Score')\n",
    "plt.xlabel('Epoch')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2 --> EfficientNetB0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T00:12:25.657218Z",
     "iopub.status.busy": "2024-08-04T00:12:25.656345Z",
     "iopub.status.idle": "2024-08-04T00:12:25.663213Z",
     "shell.execute_reply": "2024-08-04T00:12:25.662352Z",
     "shell.execute_reply.started": "2024-08-04T00:12:25.657183Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(url=\"https://media.licdn.com/dms/image/D4E12AQHL32j_wE3JTw/article-cover_image-shrink_720_1280/0/1669236519664?e=1727308800&v=beta&t=BM4KMl52c-TXWz0C-SCD_MbHo1_rdXaC6UWRhTNqZqo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# base_model_EfficientNetB0 = efn.EfficientNetB0(input_shape=(96,96,3), include_top=False, weights='imagenet')\n",
    "\n",
    "# model_EfficientNetB0 = Sequential([\n",
    "#     base_model_EfficientNetB0,\n",
    "    \n",
    "#     Flatten(),\n",
    "    \n",
    "#     Dense(256, activation='relu'),\n",
    "#     Dropout(0.5),\n",
    "#     Dense(32, activation='relu'),\n",
    "#     Dropout(0.5),\n",
    "#     BatchNormalization(),\n",
    "#     Dense(1, activation='sigmoid')\n",
    "# ])\n",
    "\n",
    "\n",
    "\n",
    "# model_EfficientNetB0.summary()\n",
    "\n",
    "\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, GlobalAveragePooling2D\n",
    "# import efficientnet.keras as efn\n",
    "\n",
    "# base_model_EfficientNetB0 = efn.EfficientNetB0(input_shape=(96, 96, 3), include_top=False, weights='imagenet')\n",
    "\n",
    "# model_EfficientNetB0 = Sequential([\n",
    "#     base_model_EfficientNetB0,\n",
    "    \n",
    "#     GlobalAveragePooling2D(),\n",
    "    \n",
    "#     Dense(256, activation='relu'),\n",
    "#     Dropout(0.5),\n",
    "#     Dense(32, activation='relu'),\n",
    "#     Dropout(0.5),\n",
    "#     BatchNormalization(),\n",
    "#     Dense(1, activation='sigmoid')\n",
    "# ])\n",
    "\n",
    "# model_EfficientNetB0.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# model_EfficientNetB0.compile(optimizer = tf.keras.optimizers.Nadam(0.0001),\n",
    "#               loss=tf.keras.losses.BinaryCrossentropy(from_logits = True),\n",
    "#               metrics=['accuracy', tf.keras.metrics.AUC(), f1_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# h1 = model_EfficientNetB0.fit(\n",
    "#     train_generator,\n",
    "#     steps_per_epoch = train_steps,\n",
    "#     validation_data = validation_generator,\n",
    "#     validation_steps = val_steps,\n",
    "#     epochs = 10\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T00:15:07.721305Z",
     "iopub.status.busy": "2024-08-04T00:15:07.72093Z",
     "iopub.status.idle": "2024-08-04T00:15:09.145497Z",
     "shell.execute_reply": "2024-08-04T00:15:09.144588Z",
     "shell.execute_reply.started": "2024-08-04T00:15:07.721276Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, GlobalAveragePooling2D\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load the EfficientNetB0 model\n",
    "base_model_EfficientNetB0 = EfficientNetB0(input_shape=(96, 96, 3), include_top=False, weights='imagenet')\n",
    "\n",
    "# Add layers using Functional API\n",
    "x = GlobalAveragePooling2D()(base_model_EfficientNetB0.output)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = BatchNormalization()(x)\n",
    "outputs = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# Create the model\n",
    "model_EfficientNetB0 = Model(inputs=base_model_EfficientNetB0.input, outputs=outputs)\n",
    "\n",
    "# Compile the model\n",
    "model_EfficientNetB0.compile(optimizer=tf.keras.optimizers.Nadam(0.0001),\n",
    "                             loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                             metrics=['accuracy', tf.keras.metrics.AUC(), f1_score])\n",
    "\n",
    "# Print the model summary\n",
    "model_EfficientNetB0.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T00:15:31.196959Z",
     "iopub.status.busy": "2024-08-04T00:15:31.196576Z",
     "iopub.status.idle": "2024-08-04T00:47:36.99408Z",
     "shell.execute_reply": "2024-08-04T00:47:36.993267Z",
     "shell.execute_reply.started": "2024-08-04T00:15:31.196928Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Fit the model\n",
    "h1 = model_EfficientNetB0.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_steps,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=val_steps,\n",
    "    epochs=10\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T00:49:21.207594Z",
     "iopub.status.busy": "2024-08-04T00:49:21.207158Z",
     "iopub.status.idle": "2024-08-04T00:49:23.509738Z",
     "shell.execute_reply": "2024-08-04T00:49:23.508801Z",
     "shell.execute_reply.started": "2024-08-04T00:49:21.207548Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "history_model_B0 = merge_history([h1])\n",
    "vis_training(history_model_B0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T00:50:47.622894Z",
     "iopub.status.busy": "2024-08-04T00:50:47.622496Z",
     "iopub.status.idle": "2024-08-04T00:50:48.348802Z",
     "shell.execute_reply": "2024-08-04T00:50:48.347869Z",
     "shell.execute_reply.started": "2024-08-04T00:50:47.622862Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "acc_B0 = [0.] + h1.history['accuracy']\n",
    "val_acc_B0 = [0.] + h1.history['val_accuracy']\n",
    "\n",
    "loss_B0 = h1.history['loss']\n",
    "val_loss_B0 = h1.history['val_loss']\n",
    "\n",
    "F1_score_B0 = h1.history['f1_score']\n",
    "F1_score_valid_B0 = h1.history['val_f1_score']\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "# Plot Training and Validation Accuracy\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.plot(acc_B0, label='Training Accuracy')\n",
    "plt.plot(val_acc_B0, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "# Plot Training and Validation Loss\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.plot(loss_B0, label='Training Loss')\n",
    "plt.plot(val_loss_B0, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.ylim([0, max(max(loss_B0), max(val_loss_B0))])\n",
    "plt.title('Training and Validation Loss')\n",
    "\n",
    "# Plot Training and Validation F1 Score\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.plot(F1_score_B0, label='Training F1 Score')\n",
    "plt.plot(F1_score_valid_B0, label='Validation F1 Score')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.ylim([0, 1])\n",
    "plt.title('Training and Validation F1 Score')\n",
    "plt.xlabel('Epoch')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3 --> Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T01:04:50.485299Z",
     "iopub.status.busy": "2024-08-04T01:04:50.484363Z",
     "iopub.status.idle": "2024-08-04T01:04:50.492945Z",
     "shell.execute_reply": "2024-08-04T01:04:50.491874Z",
     "shell.execute_reply.started": "2024-08-04T01:04:50.485264Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "\n",
    "# def f1_score(y_true, y_pred):\n",
    "#     y_pred = tf.round(tf.sigmoid(y_pred))  # Convert logits to binary predictions\n",
    "#     tp = tf.reduce_sum(tf.cast(y_true * y_pred, tf.float32), axis=0)\n",
    "#     fp = tf.reduce_sum(tf.cast((1 - y_true) * y_pred, tf.float32), axis=0)\n",
    "#     fn = tf.reduce_sum(tf.cast(y_true * (1 - y_pred), tf.float32), axis=0)\n",
    "    \n",
    "#     precision = tp / (tp + fp + tf.keras.backend.epsilon())\n",
    "#     recall = tp / (tp + fn + tf.keras.backend.epsilon())\n",
    "    \n",
    "#     f1 = 2 * precision * recall / (precision + recall + tf.keras.backend.epsilon())\n",
    "#     return tf.reduce_mean(f1)\n",
    "\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "def f1_metric(y_true, y_pred):\n",
    "    y_pred = tf.round(tf.sigmoid(y_pred))  # Convert logits to binary predictions\n",
    "\n",
    "    tp = tf.reduce_sum(tf.cast(y_true * y_pred, tf.float32))\n",
    "    fp = tf.reduce_sum(tf.cast((1 - y_true) * y_pred, tf.float32))\n",
    "    fn = tf.reduce_sum(tf.cast(y_true * (1 - y_pred), tf.float32))\n",
    "\n",
    "    precision = tp / (tp + fp + tf.keras.backend.epsilon())\n",
    "    recall = tp / (tp + fn + tf.keras.backend.epsilon())\n",
    "\n",
    "    f1 = 2 * precision * recall / (precision + recall + tf.keras.backend.epsilon())\n",
    "    return tf.reduce_mean(f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T00:52:01.05844Z",
     "iopub.status.busy": "2024-08-04T00:52:01.05807Z",
     "iopub.status.idle": "2024-08-04T00:52:01.068318Z",
     "shell.execute_reply": "2024-08-04T00:52:01.067209Z",
     "shell.execute_reply.started": "2024-08-04T00:52:01.058409Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(url=\"https://www.ismrm.org/21/program-files/TeaserSlides/abstracts/images/1945/ISMRM2021-001945_Fig6.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T01:05:01.563399Z",
     "iopub.status.busy": "2024-08-04T01:05:01.563037Z",
     "iopub.status.idle": "2024-08-04T01:05:02.712684Z",
     "shell.execute_reply": "2024-08-04T01:05:02.711759Z",
     "shell.execute_reply.started": "2024-08-04T01:05:01.56337Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# img_shape=(96, 96,3)\n",
    "# base_model_Xception = tf.keras.applications.Xception(include_top= False, weights= \"imagenet\",\n",
    "#                             input_shape= img_shape, pooling= 'max')\n",
    "    \n",
    "# model_Xception = Sequential([\n",
    "#     base_model_Xception,\n",
    "#     Flatten(),\n",
    "#     Dropout(rate= 0.3),\n",
    "#     Dense(128, activation= 'relu'),\n",
    "#     Dropout(rate= 0.25),\n",
    "#     Dense(1, activation= 'sigmoid')\n",
    "# ])\n",
    "\n",
    "# model_Xception.compile(optimizer = tf.keras.optimizers.Nadam(0.0001),\n",
    "#               loss=tf.keras.losses.BinaryCrossentropy(from_logits = True),\n",
    "#               metrics=['accuracy', tf.keras.metrics.AUC(), f1_score])\n",
    "\n",
    "# model_Xception.summary()\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, GlobalAveragePooling2D\n",
    "from tensorflow.keras.applications import Xception\n",
    "\n",
    "# Define the image shape\n",
    "img_shape = (96, 96, 3)\n",
    "\n",
    "# Load the Xception base model\n",
    "base_model_Xception = Xception(include_top=False, weights='imagenet', input_shape=img_shape)\n",
    "\n",
    "# Add layers using Functional API\n",
    "x = GlobalAveragePooling2D()(base_model_Xception.output)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = BatchNormalization()(x)\n",
    "outputs = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# Create the model\n",
    "model_Xception = Model(inputs=base_model_Xception.input, outputs=outputs)\n",
    "\n",
    "# Compile the model\n",
    "model_Xception.compile(optimizer=tf.keras.optimizers.Nadam(0.0001),\n",
    "                       loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                       metrics=['accuracy', tf.keras.metrics.AUC(), f1_metric])\n",
    "\n",
    "# Print the model summary\n",
    "model_Xception.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T01:05:02.89954Z",
     "iopub.status.busy": "2024-08-04T01:05:02.899219Z",
     "iopub.status.idle": "2024-08-04T01:54:06.05793Z",
     "shell.execute_reply": "2024-08-04T01:54:06.057046Z",
     "shell.execute_reply.started": "2024-08-04T01:05:02.899513Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "h2 = model_Xception.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch = train_steps,\n",
    "    validation_data = validation_generator,\n",
    "    validation_steps = val_steps,\n",
    "    epochs = 10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T01:54:06.062135Z",
     "iopub.status.busy": "2024-08-04T01:54:06.061269Z",
     "iopub.status.idle": "2024-08-04T01:54:07.144223Z",
     "shell.execute_reply": "2024-08-04T01:54:07.143151Z",
     "shell.execute_reply.started": "2024-08-04T01:54:06.062106Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "history_model_Xception = merge_history([h2])\n",
    "vis_training(history_model_Xception)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T01:56:04.974699Z",
     "iopub.status.busy": "2024-08-04T01:56:04.974339Z",
     "iopub.status.idle": "2024-08-04T01:56:05.737555Z",
     "shell.execute_reply": "2024-08-04T01:56:05.736643Z",
     "shell.execute_reply.started": "2024-08-04T01:56:04.974671Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "acc_Xception = [0.] + h2.history['accuracy']\n",
    "val_acc_Xception = [0.] + h2.history['val_accuracy']\n",
    "\n",
    "loss_Xception = h2.history['loss']\n",
    "val_loss_Xception = h2.history['val_loss']\n",
    "\n",
    "F1_score_Xception = h2.history['f1_metric']\n",
    "F1_score_valid_Xception = h2.history['val_f1_metric']\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "# Plot Training and Validation Accuracy\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.plot(acc_Xception, label='Training Accuracy')\n",
    "plt.plot(val_acc_Xception, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "# Plot Training and Validation Loss\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.plot(loss_Xception, label='Training Loss')\n",
    "plt.plot(val_loss_Xception, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.ylim([0, max(max(loss_Xception), max(val_loss_Xception))])\n",
    "plt.title('Training and Validation Loss')\n",
    "\n",
    "# Plot Training and Validation F1 Score\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.plot(F1_score_Xception, label='Training F1 Score')\n",
    "plt.plot(F1_score_valid_Xception, label='Validation F1 Score')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('f1_metric')\n",
    "plt.ylim([0, 1])\n",
    "plt.title('Training and Validation F1 Score')\n",
    "plt.xlabel('Epoch')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 4 --> DenseNet121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(url=\"https://www.researchgate.net/publication/357102154/figure/fig1/AS:1101806226681856@1639702483586/DenseNet121-architecture-with-three-dense-blocks-Layers-between-two-adjacent-blocks-are_W640.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# from tensorflow.keras.applications import DenseNet121\n",
    "\n",
    "# base_model_DenseNet121 = DenseNet121(input_shape=(96, 96, 3), include_top=False, weights='imagenet')\n",
    "\n",
    "# model_DenseNet121 = Sequential([\n",
    "#     base_model_DenseNet121,\n",
    "    \n",
    "#     Flatten(),\n",
    "    \n",
    "#     Dense(256, activation='relu'),\n",
    "#     Dropout(0.5),\n",
    "#     Dense(32, activation='relu'),\n",
    "#     Dropout(0.5),\n",
    "#     BatchNormalization(),\n",
    "#     Dense(1, activation='sigmoid')\n",
    "# ])\n",
    "\n",
    "# # Compile the model\n",
    "# model_DenseNet121.compile(optimizer = tf.keras.optimizers.Nadam(0.0001),\n",
    "#               loss=tf.keras.losses.BinaryCrossentropy(from_logits = True),\n",
    "#               metrics=['accuracy', tf.keras.metrics.AUC(), f1_score])\n",
    "\n",
    "# # Print the model summary\n",
    "# model_DenseNet121.summary()\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, BatchNormalization, GlobalAveragePooling2D\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "\n",
    "# Define the image shape\n",
    "img_shape = (96, 96, 3)\n",
    "\n",
    "# Load the DenseNet121 base model\n",
    "base_model_DenseNet121 = DenseNet121(input_shape=img_shape, include_top=False, weights='imagenet')\n",
    "\n",
    "# Add layers using Functional API\n",
    "x = GlobalAveragePooling2D()(base_model_DenseNet121.output)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = BatchNormalization()(x)\n",
    "outputs = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# Create the model\n",
    "model_DenseNet121 = Model(inputs=base_model_DenseNet121.input, outputs=outputs)\n",
    "\n",
    "# Compile the model\n",
    "model_DenseNet121.compile(optimizer=tf.keras.optimizers.Nadam(0.0001),\n",
    "                          loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                          metrics=['accuracy', tf.keras.metrics.AUC(), f1_score])\n",
    "\n",
    "# Print the model summary\n",
    "model_DenseNet121.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "h3 = model_DenseNet121.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch = train_steps,\n",
    "    validation_data = validation_generator,\n",
    "    validation_steps = val_steps,\n",
    "    epochs = 10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "history_model_DenseNet121 = merge_history([h3])\n",
    "vis_training(history_model_DenseNet121)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "acc_DenseNet121 = [0.] + h3.history['accuracy']\n",
    "val_acc_DenseNet121 = [0.] + h3.history['val_accuracy']\n",
    "\n",
    "loss_DenseNet121 = h3.history['loss']\n",
    "val_loss_DenseNet121 = h3.history['val_loss']\n",
    "\n",
    "F1_score_DenseNet121 = h3.history['f1_score']\n",
    "F1_score_valid_DenseNet121 = h3.history['val_f1_score']\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "# Plot Training and Validation Accuracy\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.plot(acc_DenseNet121, label='Training Accuracy')\n",
    "plt.plot(val_acc_DenseNet121, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "# Plot Training and Validation Loss\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.plot(loss_DenseNet121, label='Training Loss')\n",
    "plt.plot(val_loss_DenseNet121, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.ylim([0, max(max(loss_DenseNet121), max(val_loss_DenseNet121))])\n",
    "plt.title('Training and Validation Loss')\n",
    "\n",
    "# Plot Training and Validation F1 Score\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.plot(F1_score_DenseNet121, label='Training F1 Score')\n",
    "plt.plot(F1_score_valid_DenseNet121, label='Validation F1 Score')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.ylim([0, 1])\n",
    "plt.title('Training and Validation F1 Score')\n",
    "plt.xlabel('Epoch')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 862157,
     "sourceId": 11848,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30746,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
